{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2\n", "import mediapipe as mp\n", "from mediapipe.python.solutions.drawing_utils import draw_landmarks\n", "import math\n", "from ctypes import cast, POINTER\n", "from comtypes import CLSCTX_ALL\n", "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n", "import numpy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["devices = AudioUtilities.GetSpeakers()\n", "interface = devices.Activate(\n", "    IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n", "volume = cast(interface, POINTER(IAudioEndpointVolume))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["olume.GetMasterVolumeLevel()<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cap = cv2.VideoCapture(0)\n", "mpHands = mp.solutions.hands\n", "hands = mpHands.Hands()\n", "mpDraw = mp.solutions.drawing_utils"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["while True:\n", "    success , img =cap.read()\n", "    imgRGB = cv2.cvtColor(img , cv2.COLOR_BGR2RGB)\n", "    results = hands.process(imgRGB)\n", "    #print(results.multi_hand_landmarks)\n", "    if results.multi_hand_landmarks:\n", "        for handLms in results.multi_hand_landmarks:\n", "            lmList = []\n", "            for id ,lm in enumerate(handLms.landmark):\n", "                #print(id , lm)\n", "                h ,w , c = img.shape\n", "                cx ,cy = int(lm.x*w) , int(lm.y*h)\n", "                lmList.append([id ,cx, cy])\n", "                mpDraw.draw_landmarks(img , handLms ,mpHands.HAND_CONNECTIONS)\n", "            \n", "        if lmList:\n", "            x1 ,y1  = lmList[4][1] , lmList[4][2]\n", "            x2, y2  = lmList[8][1], lmList[8][2]\n", "            cv2.circle(img , (x1, y1) , 15 ,(255,0,0) , cv2.FILLED )\n", "            cv2.circle(img , (x2, y2) , 15 ,(255,0,0) , cv2.FILLED )\n", "            cv2.line(img , (x1 , y1) , (x2 , y2) ,(255 , 0 , 255) , 3)\n", "            z1 , z2 = (x1+x2)//2 , (y1+y2)//2\n", "            length = math.hypot(x2- x1 , y2- y1)\n", "            if length<50 :\n", "                cv2.circle(img , (z1 ,z2) ,15 , (255 , 255 , 255) ,cv2.FILLED)\n", "            \n", "            #print(length)\n", "            \n", "            #volume.GetMute()\n", "        volRange  = volume.GetVolumeRange()\n", "        minVol = volRange[0]\n", "        maxVol = volRange[1]\n", "        vol = numpy.interp(length , [50 ,300] , [minVol ,maxVol])\n", "        volBar = numpy.interp(length , [50 ,300] , [400 ,150])\n", "        volPer = numpy.interp(length , [50 ,300] , [0 ,100])\n\n", "        #length =50  ===> volPer =0\n", "        #length = 300 ===>volPer =100\n", "        #length = 175 ==> volPer = 50\n", "        #print(vol)\n", "        #print(int(length) , vol)\n", "        #print(minVol ,maxVol)\n", "        volume.SetMasterVolumeLevel(vol, None)\n", "        cv2.rectangle(img , (50 ,150) , (85 , 400) ,(123,213,122) ,3)\n", "        cv2.rectangle(img , (50 , int(volBar)) , (85 ,400) ,(0, 231,23) ,cv2.FILLED)\n", "        cv2.putText(img , str(int(volPer)) , (40, 450) ,cv2.FONT_HERSHEY_PLAIN ,4 , (24,34,34) , 3)\n", "        \n", "    cv2.imshow(\"Image\" ,img)\n", "    cv2.waitKey(1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Length of line ===50, 300<br>\n", "Range of sound is ===-21, 20<br>\n", "Range of actual volume === 0,100"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}